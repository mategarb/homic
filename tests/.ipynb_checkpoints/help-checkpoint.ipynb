{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfe50944-f85b-4528-a1f3-d25c1f2cf20e",
   "metadata": {},
   "source": [
    "# Help for the homic package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ea64c77-32ca-4c68-9a58-4167949f6bea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "sys.path.append('/gpfs/commons/home/mgarbulowski/homic_package/src')\n",
    "from homic import file_readers, simulate_16S, kraken2, dl_model, dl_evaluation, process_data, make_plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268435ef-8c10-4134-8c77-4a6e28871b03",
   "metadata": {},
   "source": [
    "## Module: file_readers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5eff0bb4-035e-46f6-a656-c5bdafadf823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function fasta in module homic.file_readers:\n",
      "\n",
      "fasta(path)\n",
      "    Reads fasta file and prints the number of organisms in the file.\n",
      "    \n",
      "    No default parameters. All must be specified.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    path : string,\n",
      "        path to the .fasta file.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    fasta_dict\n",
      "        a dictionary with organisms included in the .fasta file\n",
      "\n",
      "Help on function fastq in module homic.file_readers:\n",
      "\n",
      "fastq(path)\n",
      "    Reads fastq file.\n",
      "    \n",
      "    No default parameters. All must be specified.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    path : string,\n",
      "        path to the .fasta file.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    r2_header_lines\n",
      "        a list of all fastq headers\n",
      "    r2_read_lines\n",
      "        a list of reads\n",
      "    r2_qual_lines\n",
      "        a list of all quality lines\n",
      "\n",
      "Help on function save_fastq_as_rev_comp in module homic.file_readers:\n",
      "\n",
      "save_fastq_as_rev_comp(path)\n",
      "    Reads fastq file and creates new fastq with reverse complementary reads.\n",
      "    \n",
      "    No default parameters. All must be specified.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    path : string,\n",
      "        path to the .fastq file.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    no outputs\n",
      "        new file is created with the same name + \"_rc.fastq\" extension\n",
      "\n",
      "Help on function save_fasta_as_rev_comp in module homic.file_readers:\n",
      "\n",
      "save_fasta_as_rev_comp(path)\n",
      "    Reads fasta file and creates new fasta with reverse complementary sequences.\n",
      "    \n",
      "    No default parameters. All must be specified.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    path : string,\n",
      "        path to the .fasta file.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    no outputs\n",
      "        new file is created with the same name + \"_rc.fasta\" extension\n",
      "\n",
      "Help on function load_barcodes in module homic.file_readers:\n",
      "\n",
      "load_barcodes(path)\n",
      "    Reads .txt file with barcodes.\n",
      "    Assumes three columns: barcode sequence, x and y cooridnates.\n",
      "    \n",
      "    No default parameters. All must be specified.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    path : string,\n",
      "        path to the .txt file.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    bcodes\n",
      "        a data frame with barcodes\n",
      "\n",
      "Help on function make_benchmark_table in module homic.file_readers:\n",
      "\n",
      "make_benchmark_table(path, reads, krk_preds, bcodes)\n",
      "    Creates a table for benchmarking spots.\n",
      "    \n",
      "    No default parameters. All must be specified.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    path : string,\n",
      "        path to the gold truth species / genus list.\n",
      "    reads : list,\n",
      "        \"reads\" list read with the file_readers.fastq function\n",
      "    krk_preds : pandas Series,\n",
      "        taken as a column \"taxa\" from output of file_readers.load_kraken2_output(path)\n",
      "    bcodes : pandas DataFrame,\n",
      "        the output from file_readers.load_barcodes(path)\n",
      "        \n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    fastq_spot_d\n",
      "        a dict indicating which coordinates (spots) belong to what read. Keys are spot IDs, values are reads IDs.\n",
      "    info\n",
      "        pandas DataFrame with following columns:\n",
      "        'fastq' - fastq full header\n",
      "        'tile' - tile id (from header)\n",
      "        'x' - position x  (from header)\n",
      "        'y' - position y (from header)\n",
      "        'taxa1' - species part I, truth\n",
      "        'taxa2' - species part II, truth\n",
      "        'read' - read sequence \n",
      "        'taxa_predictions' - taxid of predictions from Kraken2\n",
      "        'taxa' - truth species, truth\n",
      "        'taxa_order' - truth taxa information, ordered \n",
      "        'superkingdom' - taxid predictions from Kraken2 translated to taxa info via ete3\n",
      "        'phylum' - taxid predictions from Kraken2 translated to taxa info via ete3\n",
      "        'class' - taxid predictions from Kraken2 translated to taxa info via ete3\n",
      "        'order' - taxid predictions from Kraken2 translated to taxa info via ete3\n",
      "        'family' - taxid predictions from Kraken2 translated to taxa info via ete3\n",
      "        'genus' - taxid predictions from Kraken2 translated to taxa info via ete3\n",
      "        'species' - taxid predictions from Kraken2 translated to taxa info via ete3\n",
      "        'barcode' - barcode sequence\n",
      "        'Bx' - barcode position X, spot definition (for synthetic data, assigned randomly)\n",
      "        'By' - barcode position Y, spot definition (for synthetic data, assigned randomly)\n",
      "\n",
      "Help on function load_kraken2_output in module homic.file_readers:\n",
      "\n",
      "load_kraken2_output(path)\n",
      "    Loads the output of kraken2 stored in the .csv file.\n",
      "    \n",
      "    No default parameters. All must be specified.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    path : string,\n",
      "        path to the .csv file.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    info\n",
      "        a data frame with following columns: 'class', 'read_id', 'species', 'read_length','kmers' and 'taxid'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(file_readers.fasta)\n",
    "help(file_readers.fastq)\n",
    "help(file_readers.save_fastq_as_rev_comp)\n",
    "help(file_readers.save_fasta_as_rev_comp)\n",
    "help(file_readers.load_barcodes)\n",
    "help(file_readers.make_benchmark_table)\n",
    "help(file_readers.load_kraken2_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d8e07c-a1b3-4e4a-8100-858b34d0db6b",
   "metadata": {},
   "source": [
    "## Module: simulate_16S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b244fd9d-875f-421e-87da-54d9fe304006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function training_data in module homic.simulate_16S:\n",
      "\n",
      "training_data(n_reads, output_path, score_thr, mic_refs, r2_header_lines, r2_read_lines, r2_qual_lines, impute_errors=True, trunc_range=[0, 0], print_stats=True)\n",
      "    Creates data for training DL model with feature selection based on alignment scores.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    n_reads : intiger,\n",
      "       number of reads to generate. In case this number exceeds the number of reads in real data, randomly (with replecement) generated reads are created.\n",
      "    output_path : string,\n",
      "       path to the foler where simulated data are created\n",
      "    score_thr : float,\n",
      "       threshold for feature selection (alignment score threshold)\n",
      "    mic_refs : dict,\n",
      "       a dict of micriobiome references\n",
      "    r2_header_lines : list,\n",
      "       a list of headers from the real data\n",
      "    r2_read_lines : list,\n",
      "       a list of reads (sequences) from the real data\n",
      "    r2_qual_lines : list,\n",
      "       a list of quality lines from the real data\n",
      "    impute_errors : boolean,\n",
      "       if True, imputes a random error in read sequences\n",
      "    trunc_range : list,\n",
      "       a list of two values, percenatage of truncation from left and right end of the read\n",
      "    print_stats : boolean,\n",
      "       if True, prints a basic statistic for simulated data\n",
      "       \n",
      "       \n",
      "    Returns\n",
      "    -------\n",
      "    all_scores\n",
      "        a list of alignment scores\n",
      "    start_vec\n",
      "        a list of starting points where reads where drawn based on the references\n",
      "    qual_vec\n",
      "        a list of qualities\n",
      "    species_list\n",
      "        a list of species (gold truth)\n",
      "\n",
      "Help on function training_data_fast in module homic.simulate_16S:\n",
      "\n",
      "training_data_fast(n_reads, output_path, mic_refs, r2_header_lines, r2_read_lines, r2_qual_lines, impute_errors=True, trunc_range=[0, 0], print_stats=True)\n",
      "    Creates data for training DL model without feature selection (fast approach).\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    n_reads : intiger,\n",
      "       number of reads to generate. In case this number exceeds the number of reads in real data, randomly (with replecement) generated reads are created.\n",
      "    output_path : string,\n",
      "       path to the foler where simulated data are created\n",
      "    mic_refs : dict,\n",
      "       a dict of micriobiome references\n",
      "    r2_header_lines : list,\n",
      "       a list of headers from the real data\n",
      "    r2_read_lines : list,\n",
      "       a list of reads (sequences) from the real data\n",
      "    r2_qual_lines : list,\n",
      "       a list of quality lines from the real data\n",
      "    impute_errors : boolean,\n",
      "       if True, imputes a random error in read sequences\n",
      "    trunc_range : list,\n",
      "       a list of two values, percenatage of truncation from left and right end of the read\n",
      "    print_stats : boolean,\n",
      "       if True, prints a basic statistic for simulated data\n",
      "       \n",
      "       \n",
      "    Returns\n",
      "    -------\n",
      "    start_vec\n",
      "        a list of starting points where reads where drawn based on the references\n",
      "    qual_vec\n",
      "        a list of qualities\n",
      "    head_vec\n",
      "        a list of headers\n",
      "    species_list\n",
      "        a list of species (gold truth)\n",
      "\n",
      "Help on function validation_data in module homic.simulate_16S:\n",
      "\n",
      "validation_data(n_reads, output_path, mic_refs, r2_header_lines, r2_read_lines, r2_qual_lines, species_tra=None, error_rate=0.001, error_weights=(1, 2, 0), trunc_range=[0, 0], print_stats=True, shuffle=True)\n",
      "    Creates data for validation with equal distribution of species and tuned error.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    n_reads : intiger,\n",
      "       number of reads to generate per taxa reference. In case this number exceeds the number of reads in real data, randomly (with replecement) generated reads are created.\n",
      "    output_path : string,\n",
      "       path to the foler where simulated data are created\n",
      "    mic_refs : dict,\n",
      "       a dict of micriobiome references\n",
      "    r2_header_lines : list,\n",
      "       a list of headers from the real data\n",
      "    r2_read_lines : list,\n",
      "       a list of reads (sequences) from the real data\n",
      "    r2_qual_lines : list,\n",
      "       a list of quality lines from the real data\n",
      "    species_tra : \"None\" or list,\n",
      "       given the list of taxa names, removes taxa that not match    \n",
      "    error_rate : float,\n",
      "       error rate for swtiching a nucleotide\n",
      "    error_weights : vector,\n",
      "       three element vector indicates a chance of getting single, double or triple error\n",
      "    trunc_range : list,\n",
      "       a list of two values, percenatage of truncation from left and right end of the read\n",
      "    print_stats : boolean,\n",
      "       if True, prints a basic statistic for simulated data\n",
      "    shuffle : boolean,\n",
      "       if True, shuffles final data as originally data are generated ordered by taxa names\n",
      "       \n",
      "       \n",
      "    Returns\n",
      "    -------\n",
      "    seq_lns\n",
      "        a list of sequences lengths\n",
      "    start_vec\n",
      "        a list of starting points where reads where drawn based on the references\n",
      "    species_list\n",
      "        a list of species (gold truth)\n",
      "    frequency\n",
      "        a dict of taxa frequencies\n",
      "\n",
      "Help on function simulate_barcodes in module homic.simulate_16S:\n",
      "\n",
      "simulate_barcodes(b_dim1, b_dim2, b_len=18)\n",
      "    Simulates barcodes and their coordinates.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    b_dim1 : integer,\n",
      "        first spatial dimension (x)\n",
      "    b_dim2 : integer,\n",
      "        second spatial dimension (y)\n",
      "    b_len : integer,\n",
      "        length of barcode [bp]\n",
      "        \n",
      "    Returns\n",
      "    -------\n",
      "    df\n",
      "        a data frame of barcodes and their x and y coordinates\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(simulate_16S.training_data)\n",
    "help(simulate_16S.training_data_fast)\n",
    "help(simulate_16S.validation_data)\n",
    "help(simulate_16S.simulate_barcodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d9b91a-ef5a-46c0-b78a-0865fbb6fdf3",
   "metadata": {},
   "source": [
    "## Module: kraken2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "710ccfc4-766b-497e-9828-c505f849c5b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function prepare_db in module homic.kraken2:\n",
      "\n",
      "prepare_db(db_path, ref_path)\n",
      "    Builds db for kraken2.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    db_path : string,\n",
      "        a path to the folder where kraken db will be created\n",
      "    ref_path : string,\n",
      "        a path to the input .fasta file with reference sequences\n",
      "        \n",
      "    Returns\n",
      "    -------\n",
      "    no output\n",
      "        files are saved to the folder under \"db_path\"\n",
      "\n",
      "Help on function classify in module homic.kraken2:\n",
      "\n",
      "classify(db_path, input_file, confidence=0.01, threads=8, min_hit_gr=2)\n",
      "    Classifies reads to genus / species according to db.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    db_path : string,\n",
      "        a path to kraken db\n",
      "    input_file : string,\n",
      "        a path to input .fastq file\n",
      "    confidence : float,\n",
      "        kraken2 parameter - confidence (-T)\n",
      "    threads : intiger,\n",
      "        kraken2 parameter - number of threads (-p)\n",
      "    min_hit_gr : intiger,\n",
      "        kraken2 parameter - minimum hitting group (-g)\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    output\n",
      "        a data frame with following columns 'outcome', 'seqid', 'taxid', 'seqlen' and 'kmers'\n",
      "\n",
      "Help on function decontaminate_single in module homic.kraken2:\n",
      "\n",
      "decontaminate_single(db_path, input_file, output, confidence=0.5, threads=8, min_base_qual=22)\n",
      "    Decontamination with kraken2 for single .fastq (unpaired).\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    db_path : string,\n",
      "        a path to kraken db\n",
      "    input_file : string,\n",
      "        a path to the .fastq file\n",
      "    output : string,\n",
      "        a path to the output .fastq file where host reads are removed\n",
      "    confidence : float,\n",
      "        kraken2 parameter - confidence (--confidence)\n",
      "    threads : intiger,\n",
      "        kraken2 parameter - number of threads (--threads)\n",
      "    min_base_qual : intiger,\n",
      "        kraken2 parameter - minimum base quality (--minimum-base-quality)\n",
      "        \n",
      "    Returns\n",
      "    -------\n",
      "    no output, files are saved under \"output\"\n",
      "\n",
      "Help on function decontaminate_paired in module homic.kraken2:\n",
      "\n",
      "decontaminate_paired(db_path, input_file1, input_file2, output, confidence=0.5, threads=12, min_base_qual=22)\n",
      "    Decontamination with kraken2 for paired .fastq files.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    db_path : string,\n",
      "        a path to kraken db\n",
      "    input_file1 : string,\n",
      "        a path to the first .fastq file\n",
      "    input_file2 : string,\n",
      "        a path to the second .fastq file\n",
      "    output : string,\n",
      "        a path to the output .fastq file where host reads are removed\n",
      "    confidence : float,\n",
      "        kraken2 parameter - confidence (--confidence)\n",
      "    threads : intiger,\n",
      "        kraken2 parameter - number of threads (--threads)\n",
      "    min_base_qual : intiger,\n",
      "        kraken2 parameter - minimum base quality (--minimum-base-quality)\n",
      "        \n",
      "    Returns\n",
      "    -------\n",
      "    no output, files are saved under \"output\"\n",
      "\n",
      "Help on function evaluate_kraken in module homic.kraken2:\n",
      "\n",
      "evaluate_kraken(krk_path, gs_path)\n",
      "    Evaluates kraken2 prediction with gold standard.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    krk_path : string,\n",
      "        a path to kraken2 result (.csv)\n",
      "    gs_path : string,\n",
      "        a path to the gold stanard file (.txt)\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "        a value of accuracy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(kraken2.prepare_db)\n",
    "help(kraken2.classify)\n",
    "help(kraken2.decontaminate_single)\n",
    "help(kraken2.decontaminate_paired)\n",
    "help(kraken2.evaluate_kraken)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a467e224-c453-41cb-9479-66dd4540f062",
   "metadata": {},
   "source": [
    "## Module: dl_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6b43693-8ff8-40bc-9670-b7e03c6c3caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function prepare_data in module homic.dl_model:\n",
      "\n",
      "prepare_data(input_fq, ref_d, taxa_skip=False, asf=False)\n",
      "    Prepares the data for encoding and learning.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    input_fq : string,\n",
      "        a path to .fastq file\n",
      "    ref_d : string,\n",
      "        an output from \"file_readers.species_outcome()\"\n",
      "    taxa_skip : boolean,\n",
      "        if true, skips taxa info and uses labels. Otherwise, runs taxa assignment via ete3.\n",
      "    asf : boolean,\n",
      "        use ASF species names instead of ASF id's.\n",
      "        \n",
      "    Returns\n",
      "    -------\n",
      "    df_merge\n",
      "        a data frame with reads and taxonomic assignments\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(dl_model.prepare_data)\n",
    "help(dl_model.one_hot_encoder)\n",
    "help(dl_model.one_hot_model)\n",
    "help(dl_model.predict_class_for_reads)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452bda82-1225-482c-9345-0fa044a4678e",
   "metadata": {},
   "source": [
    "## Module: dl_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59e4c03-5cfa-49f6-8ed5-1c3be29cbc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(dl_evaluation.reassign_classes_per_spot)\n",
    "help(dl_evaluation.merge_prediction_results)\n",
    "help(dl_evaluation.per_spot_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352db6b7-da86-4e4e-a069-c222d2645f44",
   "metadata": {},
   "source": [
    "## Module: process_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e55f95-c31e-4d89-9ba8-457d826615bc",
   "metadata": {},
   "source": [
    "## Module: make_plots"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
